{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XtFQP3RNll3c"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7026,
     "status": "ok",
     "timestamp": 1618423490594,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "443CZCLp0_sE",
    "outputId": "ddda53b2-a593-4d13-ee48-cfed23e613b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kirillanpilov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqDHq_AEjRZ1"
   },
   "source": [
    "## 1. Представление и предобработка текстовых данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaki7efDpmXo"
   },
   "source": [
    "### 1.1 Операции по предобработке:\n",
    "* токенизация\n",
    "* стемминг / лемматизация\n",
    "* удаление стоп-слов\n",
    "* удаление пунктуации\n",
    "* приведение к нижнему регистру\n",
    "* любые другие операции над текстом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nHRy4jpYphEr"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lMMzGhq0ikz1"
   },
   "outputs": [],
   "source": [
    "text = 'Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. Note that LibTorch is only available for C++'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUhfertRtXE5"
   },
   "source": [
    "Реализовать функцию `preprocess_text(text: str)`, которая:\n",
    "* приводит строку к нижнему регистру\n",
    "* заменяет все символы, кроме a-z, A-Z и знаков .,!? на пробел\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z .,!?]',' ', text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select your preferences and run the install command. stable represents the most currently tested and supported version of pytorch. note that libtorch is only available for c  '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2Dt1ssIqckC"
   },
   "source": [
    "### 1.2 Представление текстовых данных при помощи бинарного кодирования\n",
    "\n",
    "\n",
    "Представить первое предложение из `text` в виде тензора `sentence_t`: `sentence_t[i] == 1`, если __слово__ с индексом `i` присуствует в предложении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_sen(text: str) -> torch.Tensor():\n",
    "    #vocab of unique words\n",
    "    vocab = list(set(word_tokenize(text)))\n",
    "\n",
    "    #First sentence \n",
    "    sen1 = sent_tokenize(text)[0]\n",
    "\n",
    "    #zero tensor \n",
    "    tensor_sen = torch.zeros(len(vocab))\n",
    "    \n",
    "    for word in word_tokenize(sen1):\n",
    "        tensor_sen[vocab.index(word)] = 1\n",
    "  \n",
    "    return tensor_sen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 1., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_sen(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2Nz_zcgw3N4"
   },
   "source": [
    "## 2. Классификация фамилий по национальности\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/owHew8hzPc7X9Q?w=1\n",
    "\n",
    "2.1 Считать файл `surnames/surnames.csv`. \n",
    "\n",
    "2.2 Закодировать национальности числами, начиная с 0.\n",
    "\n",
    "2.3 Разбить датасет на обучающую и тестовую выборку\n",
    "\n",
    "2.4 Реализовать класс `Vocab` (токен = __символ__)\n",
    "\n",
    "2.5 Реализовать класс `SurnamesDataset`\n",
    "\n",
    "2.6. Обучить классификатор.\n",
    "\n",
    "2.7 Измерить точность на тестовой выборке. Проверить работоспособность модели: прогнать несколько фамилий студентов группы через модели и проверить результат. Для каждой фамилии выводить 3 наиболее вероятных предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Считать файл `surnames/surnames.csv`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "surnames_df = pd.read_csv('surnames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "      <th>nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Woodford</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coté</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Koury</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lebzak</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    surname nationality\n",
       "0  Woodford     English\n",
       "1      Coté      French\n",
       "2      Kore     English\n",
       "3     Koury      Arabic\n",
       "4    Lebzak     Russian"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Закодировать национальности числами, начиная с 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "      <th>nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Woodford</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coté</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kore</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Koury</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lebzak</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    surname  nationality\n",
       "0  Woodford            4\n",
       "1      Coté            5\n",
       "2      Kore            4\n",
       "3     Koury            0\n",
       "4    Lebzak           14"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(surnames_df['nationality'])\n",
    "surnames_df['nationality'] = le.transform(surnames_df['nationality'])\n",
    "surnames_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arabic' 'Chinese' 'Czech' 'Dutch' 'English' 'French' 'German' 'Greek'\n",
      " 'Irish' 'Italian' 'Japanese' 'Korean' 'Polish' 'Portuguese' 'Russian'\n",
      " 'Scottish' 'Spanish' 'Vietnamese']\n"
     ]
    }
   ],
   "source": [
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Разбить датасет на обучающую и тестовую выборку\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(surnames_df['surname'], surnames_df['nationality'] , test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Реализовать класс `Vocab` (токен = __символ__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "kUkSZkDqxNYS"
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, data: pd.Series):\n",
    "        self.data = data\n",
    "        self.token_to_idx = self.create_vocab(self.data)\n",
    "        self.idx_to_token = {token: symbol for symbol, token  in self.token_to_idx.items()}\n",
    "        self.vocab_len = len(self.token_to_idx)\n",
    "\n",
    "\n",
    "    def create_vocab(self, data):\n",
    "        token_to_idx = {}\n",
    "        str_data = \" \".join(data)\n",
    "        tokenizer = 0\n",
    "        for symbol in str_data:\n",
    "            if symbol not in token_to_idx:\n",
    "                token_to_idx[symbol] = tokenizer\n",
    "                tokenizer += 1\n",
    "            \n",
    "        return token_to_idx\n",
    "\n",
    "  \n",
    "      \n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 's': 1,\n",
       " 'u': 2,\n",
       " 'l': 3,\n",
       " 'i': 4,\n",
       " 'v': 5,\n",
       " 'a': 6,\n",
       " 'n': 7,\n",
       " ' ': 8,\n",
       " 'S': 9,\n",
       " 'e': 10,\n",
       " 'o': 11,\n",
       " 'w': 12,\n",
       " 'D': 13,\n",
       " 'r': 14,\n",
       " 't': 15,\n",
       " 'E': 16,\n",
       " 'j': 17,\n",
       " 'd': 18,\n",
       " 'I': 19,\n",
       " 'A': 20,\n",
       " 'h': 21,\n",
       " 'M': 22,\n",
       " 'f': 23,\n",
       " 'G': 24,\n",
       " 'k': 25,\n",
       " 'L': 26,\n",
       " 'y': 27,\n",
       " 'H': 28,\n",
       " 'm': 29,\n",
       " 'J': 30,\n",
       " 'R': 31,\n",
       " 'g': 32,\n",
       " 'P': 33,\n",
       " 'b': 34,\n",
       " 'T': 35,\n",
       " 'c': 36,\n",
       " 'K': 37,\n",
       " 'B': 38,\n",
       " 'W': 39,\n",
       " 'z': 40,\n",
       " 'p': 41,\n",
       " 'q': 42,\n",
       " 'Y': 43,\n",
       " 'N': 44,\n",
       " 'V': 45,\n",
       " 'F': 46,\n",
       " 'C': 47,\n",
       " 'U': 48,\n",
       " 'Z': 49,\n",
       " 'ñ': 50,\n",
       " 'ò': 51,\n",
       " 'Q': 52,\n",
       " 'x': 53,\n",
       " 'X': 54,\n",
       " \"'\": 55,\n",
       " 'é': 56,\n",
       " 'ü': 57,\n",
       " 'ó': 58,\n",
       " 'á': 59,\n",
       " 'ö': 60,\n",
       " 'à': 61,\n",
       " 'ã': 62,\n",
       " 'ß': 63,\n",
       " 'è': 64,\n",
       " ':': 65,\n",
       " 'ä': 66,\n",
       " '1': 67,\n",
       " 'í': 68,\n",
       " 'ú': 69,\n",
       " '-': 70,\n",
       " 'É': 71,\n",
       " 'Ż': 72,\n",
       " 'õ': 73,\n",
       " 'ç': 74,\n",
       " 'Ś': 75,\n",
       " 'ì': 76,\n",
       " '/': 77,\n",
       " 'ń': 78,\n",
       " 'ê': 79,\n",
       " 'Á': 80}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Vocab(X_train)\n",
    "vocab.token_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Реализовать класс `SurnamesDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "executionInfo": {
     "elapsed": 1303,
     "status": "error",
     "timestamp": 1619117849212,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "WCaRK1QHxe0A",
    "outputId": "5d1243af-d0dd-4922-9468-9618f5df4605"
   },
   "outputs": [],
   "source": [
    "class SurnamesDataset(Dataset):\n",
    "    def __init__(self, X, y, vocab: Vocab):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def vectorize(self, surname):\n",
    "        '''Генерирует представление фамилии surname в при помощи бинарного кодирования (см. 1.2)'''\n",
    "        surname_tensor = torch.zeros(self.vocab.vocab_len)\n",
    "        \n",
    "        for symbol in surname:\n",
    "            surname_tensor[self.vocab.token_to_idx[symbol]] = 1\n",
    "        \n",
    "        return surname_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):      \n",
    "        return {\"target\" : X[idx] , \"label\" : y[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "surnames_dataset = SurnamesDataset(X_train, y_train, Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Vocab' has no attribute 'vocab_len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msurnames_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAynpilov\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[96], line 9\u001b[0m, in \u001b[0;36mSurnamesDataset.vectorize\u001b[0;34m(self, surname)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvectorize\u001b[39m(\u001b[38;5;28mself\u001b[39m, surname):\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Генерирует представление фамилии surname в при помощи бинарного кодирования (см. 1.2)'''\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     surname_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_len\u001b[49m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m surname:\n\u001b[1;32m     12\u001b[0m         surname_tensor[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mtoken_to_idx[symbol]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Vocab' has no attribute 'vocab_len'"
     ]
    }
   ],
   "source": [
    "surnames_dataset.vectorize('Aynpilov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    ".."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLmDB3fJtVox"
   },
   "source": [
    "## 3. Классификация обзоров ресторанов\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/nY1o70JtAuYa8g\n",
    "\n",
    "3.1 Считать файл `yelp/raw_train.csv`. Оставить от исходного датасета 10% строчек.\n",
    "\n",
    "3.2 Воспользоваться функцией `preprocess_text` из 1.1 для обработки текста отзыва. Закодировать рейтинг числами, начиная с 0.\n",
    "\n",
    "3.3 Разбить датасет на обучающую и тестовую выборку\n",
    "\n",
    "3.4 Реализовать класс `Vocab` (токен = слово)\n",
    "\n",
    "3.5 Реализовать класс `ReviewDataset`\n",
    "\n",
    "3.6 Обучить классификатор\n",
    "\n",
    "3.7 Измерить точность на тестовой выборке. Проверить работоспособность модели: придумать небольшой отзыв, прогнать его через модель и вывести номер предсказанного класса (сделать это для явно позитивного и явно негативного отзыва)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lCTSKZgu68K"
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "  def __init__(self, data):\n",
    "    self.idx_to_token = ...\n",
    "    self.token_to_idx = ...\n",
    "    self.vocab_len = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXLmCDvcvRmb"
   },
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "  def __init__(self, X, y, vocab: Vocab):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.vocab = vocab\n",
    "\n",
    "  def vectorize(self, review):\n",
    "    '''Генерирует представление отзыва review при помощи бинарного кодирования (см. 1.2)'''\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return ..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMJ70DQQj2X/XaG2BMq6jy8",
   "collapsed_sections": [],
   "name": "blank__05_NLP_1_intro.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
