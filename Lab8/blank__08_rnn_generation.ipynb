{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "LvWmvkktjM3-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKMq7dp2W15Y",
        "outputId": "0a8a61ad-4510-4c45-b08d-8b8465209fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "nltk.download('punkt')\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive"
      ],
      "metadata": {
        "id": "LOEgySl1jPz3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBkqaK5bawXN",
        "outputId": "bb97f8c5-a474-442f-8472-d4bf6202d6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qOQwNlZbFiO",
        "outputId": "50235a08-7514-4c85-9b78-97c66524585c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/datasets'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функция обучения"
      ],
      "metadata": {
        "id": "4hNQEhxOjSJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, n_epochs, train_loader, test_loader):\n",
        "\n",
        "  loss_train = []\n",
        "  accuracy_train = []\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    for batch in tqdm(train_loader, desc=f\"Training epoch {epoch + 1}/{n_epochs}\"):\n",
        "        inputs = batch[\"X\"].to(device)\n",
        "        labels = batch[\"y\"].to(device)\n",
        "        output = model(inputs)\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch in tqdm(test_loader, desc=f\"Testing epoch {epoch + 1}/{n_epochs}\"):\n",
        "        inputs = batch[\"X\"].to(device)\n",
        "        labels = batch[\"y\"].to(device)\n",
        "        output = model(inputs)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = correct / total\n",
        "    accuracy_train.append(test_accuracy)\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(epoch + 1, n_epochs, loss.item(), test_accuracy * 100))\n",
        "    loss_train.append(loss.item())\n"
      ],
      "metadata": {
        "id": "gf7NmvmVjVCf"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmWCBWxrBUB3"
      },
      "source": [
        "## 1. Генерирование русских имен при помощи RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "990obDBwCC7V"
      },
      "source": [
        "Датасет: https://disk.yandex.ru/i/2yt18jHUgVEoIw\n",
        "\n",
        "1.1 На основе файла name_rus.txt создайте датасет.\n",
        "  * Учтите, что имена могут иметь различную длину\n",
        "  * Добавьте 4 специальных токена:\n",
        "    * `<PAD>` для дополнения последовательности до нужной длины;\n",
        "    * `<UNK>` для корректной обработки ранее не встречавшихся токенов;\n",
        "    * `<SOS>` для обозначения начала последовательности;\n",
        "    * `<EOS>` для обозначения конца последовательности.\n",
        "  * Преобразовывайте строку в последовательность индексов с учетом следующих замечаний:\n",
        "    * в начало последовательности добавьте токен `<SOS>`;\n",
        "    * в конец последовательности добавьте токен `<EOS>` и, при необходимости, несколько токенов `<PAD>`;\n",
        "  * `Dataset.__get_item__` возращает две последовательности: последовательность для обучения и правильный ответ.\n",
        "  \n",
        "  Пример:\n",
        "  ```\n",
        "  s = 'The cat sat on the mat'\n",
        "  # преобразуем в индексы\n",
        "  s_idx = [2, 5, 1, 2, 8, 4, 7, 3, 0, 0]\n",
        "  # получаем x и y (__getitem__)\n",
        "  x = [2, 5, 1, 2, 8, 4, 7, 3, 0]\n",
        "  y = [5, 1, 2, 8, 4, 7, 3, 0, 0]\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read file"
      ],
      "metadata": {
        "id": "4g99rq2MRewT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/DL_FU/name_rus.txt', 'r',  encoding = 'cp1251') as file:\n",
        "  lines = file.readlines()"
      ],
      "metadata": {
        "id": "DuLQF6zeRcvJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = [line.replace('\\n', '' ) for line in lines]"
      ],
      "metadata": {
        "id": "5mnPN6xMTNQf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines"
      ],
      "metadata": {
        "id": "7X8BbCuUTbgB",
        "outputId": "f5b3266e-2112-4126-b425-a940b638e197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'яша'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocab"
      ],
      "metadata": {
        "id": "kmA7N1L_WxOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_vocab_from_iterator(lines, specials=[\"<PAD>\", \"<UNK>\", \"<SOS>\", \"<EOS>\"])\n",
        "token2inx = vocab.get_stoi()\n",
        "inx2token = {inx: token for token, inx in vocab.get_stoi().items()}"
      ],
      "metadata": {
        "id": "9OjPO7fVWzNZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token2inx"
      ],
      "metadata": {
        "id": "UcxmcRhYXImc",
        "outputId": "c65793b8-97e7-4105-f703-6cb5d539bf7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ж': 32,\n",
              " 'э': 31,\n",
              " 'з': 30,\n",
              " 'б': 29,\n",
              " 'к': 11,\n",
              " 'е': 9,\n",
              " 'о': 14,\n",
              " 'н': 5,\n",
              " 'а': 4,\n",
              " 'в': 16,\n",
              " 'ы': 28,\n",
              " 'и': 6,\n",
              " 'х': 21,\n",
              " '<SOS>': 2,\n",
              " '<EOS>': 3,\n",
              " '<UNK>': 1,\n",
              " 'я': 8,\n",
              " 'л': 7,\n",
              " '<PAD>': 0,\n",
              " 'ш': 19,\n",
              " 'с': 13,\n",
              " 'м': 15,\n",
              " 'ю': 17,\n",
              " 'у': 18,\n",
              " 'д': 20,\n",
              " 'г': 22,\n",
              " 'т': 12,\n",
              " 'п': 23,\n",
              " 'ч': 24,\n",
              " 'й': 26,\n",
              " 'ц': 33,\n",
              " 'ь': 25,\n",
              " 'р': 10,\n",
              " 'ф': 27}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### X и y"
      ],
      "metadata": {
        "id": "BWuntooJYdoC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample"
      ],
      "metadata": {
        "id": "jsayTxlhgtUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# maxlen = 40\n",
        "# step = 3\n",
        "# sentences = []\n",
        "# next_chars = []\n",
        "# for i in range(0, len(text_nietzsche) - maxlen, step):\n",
        "#     sentences.append(text_nietzsche[i: i + maxlen])\n",
        "#     next_chars.append(text_nietzsche[i + maxlen])\n",
        "# print('nb sequences:', len(sentences))\n",
        "\n",
        "# print('Vectorization...')\n",
        "# x = np.zeros((len(sentences), maxlen, len(token2inx)))\n",
        "# y = np.zeros((len(sentences), len(token2inx)))\n",
        "# for i, sentence in enumerate(sentences):\n",
        "#     for t, char in enumerate(sentence):\n",
        "#         x[i, t, token2inx[char]] = 1\n",
        "#     y[i, token2inx[next_chars[i]]] = 1\n",
        "\n",
        "\n",
        "maxlen = 3\n",
        "step = 1\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for name in lines:\n",
        "  print(name)\n",
        "  name1 = [token2inx.get(char,1) for char in name]\n",
        "  name1.insert(0, token2inx[\"<SOS>\"])\n",
        "  name1.append(token2inx[\"<EOS>\"])\n",
        "  for i in range(0, len(name) - maxlen, step):\n",
        "    print(name[i: i + maxlen], name1[i: i + maxlen])\n",
        "    print(name[i + maxlen], name1[i + maxlen])\n",
        "    X.append(name1[i: i + maxlen])\n",
        "    y.append(name1[i + maxlen])\n",
        "  break\n"
      ],
      "metadata": {
        "id": "1b-RplOaaUNa",
        "outputId": "c398d8dc-c19e-4e3e-ceee-f92ccb5c79a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "авдокея\n",
            "авд [2, 4, 16]\n",
            "о 20\n",
            "вдо [4, 16, 20]\n",
            "к 14\n",
            "док [16, 20, 14]\n",
            "е 11\n",
            "оке [20, 14, 11]\n",
            "я 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vector"
      ],
      "metadata": {
        "id": "ROvyQDJBg06-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 3\n",
        "step = 1\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for name in lines:\n",
        "  name = [token2inx.get(char,1) for char in name]\n",
        "  name.insert(0, token2inx[\"<SOS>\"])\n",
        "  name.append(token2inx[\"<EOS>\"])\n",
        "  for i in range(0, len(name) - maxlen, step):\n",
        "    X.append(name[i: i + maxlen])\n",
        "    y.append(name[i + maxlen])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "pjhplkjPYfUW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "RBzgxobWcthh",
        "outputId": "4866dda8-44c0-4129-f001-16066499eade",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2,  4, 16],\n",
              "       [ 4, 16, 20],\n",
              "       [16, 20, 14],\n",
              "       ...,\n",
              "       [16, 11,  4],\n",
              "       [ 2,  8, 19],\n",
              "       [ 8, 19,  4]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "onv_3Zj_cunD",
        "outputId": "03c063b0-5b66-4302-f513-7ce4cf20f4f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([20, 14, 11, ...,  3,  4,  3])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and test"
      ],
      "metadata": {
        "id": "S9XNzGMJlJCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = RANDOM_SEED)"
      ],
      "metadata": {
        "id": "qT0rLsQklWO6"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### class Dataset"
      ],
      "metadata": {
        "id": "Jd_K_VG4VkVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NameDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    return {\"X\" : torch.tensor(self.X[item]).to(torch.long) ,\n",
        "            \"y\" : torch.tensor(self.y[item]).to(torch.long)}"
      ],
      "metadata": {
        "id": "bZDQpXn_Vjxy"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NameDataset(X_train, y_train)\n",
        "test_dataset = NameDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "thVrAs7_XitP"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### class DataLoader"
      ],
      "metadata": {
        "id": "m6TFOo2kmwmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "train_data_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE )\n",
        "test_data_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "id": "7XQeNIcPmzkn"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ3qcpcJNCFZ"
      },
      "source": [
        "1.2 Создайте и обучите модель для генерации фамилии.\n",
        "\n",
        "  * Для преобразования последовательности индексов в последовательность векторов используйте `nn.Embedding`;\n",
        "  * Используйте рекуррентные слои;\n",
        "  * Задача ставится как предсказание следующего токена в каждом примере из пакета для каждого момента времени. Т.е. в данный момент времени по текущей подстроке предсказывает следующий символ для данной строки (задача классификации);\n",
        "  * Примерная схема реализации метода `forward`:\n",
        "  ```\n",
        "    input_X: [batch_size x seq_len] -> nn.Embedding -> emb_X: [batch_size x seq_len x embedding_size]\n",
        "    emb_X: [batch_size x seq_len x embedding_size] -> nn.RNN -> output: [batch_size x seq_len x hidden_size]\n",
        "    output: [batch_size x seq_len x hidden_size] -> torch.Tensor.reshape -> output: [batch_size * seq_len x hidden_size]\n",
        "    output: [batch_size * seq_len x hidden_size] -> nn.Linear -> output: [batch_size * seq_len x vocab_size]\n",
        "  ```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNGeneratorNames(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "      super().__init__()\n",
        "\n",
        "      self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "      self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
        "      self.fc = nn.Linear(hidden_size,1)\n",
        "\n",
        "  def forward(self, input_X):\n",
        "    emb_X = self.embedding(input_X)\n",
        "    output, _ = self.rnn(emb_X)\n",
        "\n",
        "    batch_size = output.shape[0]\n",
        "    seq_len = output.shape[1]\n",
        "    output = output.reshape(batch_size * seq_len, hidden_size)\n",
        "\n",
        "    output = self.fc(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "HYWqBjmehZmK"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(token2inx)\n",
        "embedding_dim = 6\n",
        "hidden_size = 100\n",
        "EPOCHS = 10\n",
        "\n",
        "\n",
        "modelNameGeneration = RNNGeneratorNames(vocab_size, embedding_dim, hidden_size)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(modelNameGeneration.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "nObhfs3LkEPg"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(modelNameGeneration, optimizer, criterion, EPOCHS, train_data_loader, test_data_loader)"
      ],
      "metadata": {
        "id": "ONYuL-E0krMp",
        "outputId": "cc8e6e70-cf5f-43a3-d917-018f18e4de16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "ea7b598dc81b4254ae462715279d90fc",
            "823be5fc63784875b5f6446f8e549fb0",
            "81986f5b88f44b0b8e73a619f28b2e88",
            "bda5069c2f3f4e338fd0595273bd2b69",
            "a304529fd8fa40398ed545ff500074fb",
            "ed25ee9abfa1485cb1eebbde4a6c1156",
            "036a5091f3c849959daae72bb3317834",
            "83760fbd981647c79e768a3b0059f79a",
            "c7b891d5537843d6b54ea29be2148b5b",
            "b08502af79204f628ee00fcfd9c9d1b1",
            "4b5b07b4682b4e10910dff1185235c87"
          ]
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training epoch 1/10:   0%|          | 0/128 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea7b598dc81b4254ae462715279d90fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([192, 1])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-05603099aae0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelNameGeneration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-82-fd4afcf820eb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, n_epochs, train_loader, test_loader)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (192) to match target batch_size (64)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBSI2ORFNCFZ"
      },
      "source": [
        "1.3 Напишите функцию, которая генерирует фамилию при помощи обученной модели:\n",
        "  * Построение начинается с последовательности единичной длины, состоящей из индекса токена `<SOS>`;\n",
        "  * Начальное скрытое состояние RNN `h_t = None`;\n",
        "  * В результате прогона последнего токена из построенной последовательности через модель получаете новое скрытое состояние `h_t` и распределение над всеми токенами из словаря;\n",
        "  * Выбираете 1 токен пропорционально вероятности и добавляете его в последовательность (можно воспользоваться `torch.multinomial`);\n",
        "  * Повторяете эти действия до тех пор, пока не сгенерирован токен `<EOS>` или не превышена максимальная длина последовательности.\n",
        "\n",
        "При обучении каждые `k` эпох генерируйте несколько фамилий и выводите их на экран."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJf5iaA2fOTM"
      },
      "source": [
        "## 2. Генерирование текста при помощи RNN\n",
        "\n",
        "2.1 Скачайте из интернета какое-нибудь художественное произведение\n",
        "  * Выбирайте достаточно крупное произведение, чтобы модель лучше обучалась;\n",
        "\n",
        "2.2 На основе выбранного произведения создайте датасет.\n",
        "\n",
        "Отличия от задачи 1:\n",
        "  * Токены <SOS>, `<EOS>` и `<UNK>` можно не добавлять;\n",
        "  * При создании датасета текст необходимо предварительно разбить на части. Выберите желаемую длину последовательности `seq_len` и разбейте текст на построки длины `seq_len` (можно без перекрытия, можно с небольшим перекрытием).\n",
        "\n",
        "2.3 Создайте и обучите модель для генерации текста\n",
        "  * Задача ставится точно так же как в 1.2;\n",
        "  * При необходимости можете применить:\n",
        "    * двухуровневые рекуррентные слои (`num_layers`=2)\n",
        "    * [обрезку градиентов](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
        "\n",
        "2.4 Напишите функцию, которая генерирует фрагмент текста при помощи обученной модели\n",
        "  * Процесс генерации начинается с небольшого фрагмента текста `prime`, выбранного вами (1-2 слова)\n",
        "  * Сначала вы пропускаете через модель токены из `prime` и генерируете на их основе скрытое состояние рекуррентного слоя `h_t`;\n",
        "  * После этого вы генерируете строку нужной длины аналогично 1.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh47ZvUDNCFZ"
      },
      "source": [
        "2.1 Скачайте из интернета какое-нибудь художественное произведение\n",
        "  * Выбирайте достаточно крупное произведение, чтобы модель лучше обучалась;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5UT6vQONCFZ"
      },
      "source": [
        "2.2 На основе выбранного произведения создайте датасет.\n",
        "\n",
        "Отличия от задачи 1:\n",
        "  * Токены <SOS>, `<EOS>` и `<UNK>` можно не добавлять;\n",
        "  * При создании датасета текст необходимо предварительно разбить на части. Выберите желаемую длину последовательности `seq_len` и разбейте текст на построки длины `seq_len` (можно без перекрытия, можно с небольшим перекрытием)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHLFOlkJNCFZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "blank__08_rnn_generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea7b598dc81b4254ae462715279d90fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_823be5fc63784875b5f6446f8e549fb0",
              "IPY_MODEL_81986f5b88f44b0b8e73a619f28b2e88",
              "IPY_MODEL_bda5069c2f3f4e338fd0595273bd2b69"
            ],
            "layout": "IPY_MODEL_a304529fd8fa40398ed545ff500074fb"
          }
        },
        "823be5fc63784875b5f6446f8e549fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed25ee9abfa1485cb1eebbde4a6c1156",
            "placeholder": "​",
            "style": "IPY_MODEL_036a5091f3c849959daae72bb3317834",
            "value": "Training epoch 1/10:   0%"
          }
        },
        "81986f5b88f44b0b8e73a619f28b2e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83760fbd981647c79e768a3b0059f79a",
            "max": 128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7b891d5537843d6b54ea29be2148b5b",
            "value": 0
          }
        },
        "bda5069c2f3f4e338fd0595273bd2b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b08502af79204f628ee00fcfd9c9d1b1",
            "placeholder": "​",
            "style": "IPY_MODEL_4b5b07b4682b4e10910dff1185235c87",
            "value": " 0/128 [00:00&lt;?, ?it/s]"
          }
        },
        "a304529fd8fa40398ed545ff500074fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed25ee9abfa1485cb1eebbde4a6c1156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "036a5091f3c849959daae72bb3317834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83760fbd981647c79e768a3b0059f79a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b891d5537843d6b54ea29be2148b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b08502af79204f628ee00fcfd9c9d1b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b5b07b4682b4e10910dff1185235c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}